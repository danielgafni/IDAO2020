{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T23:52:23.748394Z",
     "start_time": "2020-02-03T23:52:07.416915Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from utils import CustomDataset, smape, spherical_from_cartesian\n",
    "from models import BaselineNN, LSTM\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output, display\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T23:52:27.487165Z",
     "start_time": "2020-02-03T23:52:23.757511Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv', parse_dates=['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T23:52:27.491687Z",
     "start_time": "2020-02-03T23:52:27.488870Z"
    }
   },
   "outputs": [],
   "source": [
    "features = ['epoch', 'ro_sim', 'theta_sim', 'fi_sim', 'dro/dt_sim', 'dtheta/dt_sim', 'dfi/dt_sim']\n",
    "targets = ['ro', 'theta', 'fi', 'dro/dt', 'dtheta/dt', 'dfi/dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T23:52:31.742698Z",
     "start_time": "2020-02-03T23:52:27.493358Z"
    }
   },
   "outputs": [],
   "source": [
    "data['epoch'] = data['epoch'].apply(lambda x: x.to_pydatetime().timestamp())\n",
    "data['epoch'] = data['epoch'] - data['epoch'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T23:52:32.742045Z",
     "start_time": "2020-02-03T23:52:31.746259Z"
    }
   },
   "outputs": [],
   "source": [
    "data = spherical_from_cartesian(data)\n",
    "data[features] = data[features] / np.abs(data[features]).max(axis=0)\n",
    "data[targets] = data[targets] / np.abs(data[targets]).max(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating satellites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T23:52:41.424021Z",
     "start_time": "2020-02-03T23:52:40.049195Z"
    }
   },
   "outputs": [],
   "source": [
    "sat_datas = []\n",
    "data_grouped = data.groupby('sat_id')\n",
    "for sat_data in data_grouped:\n",
    "    sat_datas.append(sat_data[1].drop(['id', 'sat_id'], axis=1))\n",
    "sat_datas_train = []\n",
    "sat_datas_test = []\n",
    "for sat_data in sat_datas:\n",
    "    # Split data to train and test datasets\n",
    "    sat_data_train, sat_data_test = train_test_split(sat_data, shuffle=False, test_size=0.25)\n",
    "    sat_datas_train.append(sat_data_train)\n",
    "    sat_datas_test.append(sat_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T23:52:44.444995Z",
     "start_time": "2020-02-03T23:52:44.425731Z"
    }
   },
   "outputs": [],
   "source": [
    "seq_len = 5\n",
    "model = LSTM(14, seq_len=seq_len)\n",
    "criterion = smape\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.5)\n",
    "loss_widget = widgets.FloatProgress(min=0, max=1, step=0.01, description='Loss')\n",
    "loss_widget.value = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-03T23:52:49.212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffde8e21b64b4023973779dca19d3477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, description='Loss', max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5abf6015f64ec1a365bc8b6e3833f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Currently training sattlite', max=600.0, style=ProgressStâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(loss_widget)\n",
    "desc = 'satelline number'\n",
    "model.train()\n",
    "for train_data in tqdm(sat_datas_train, desc=desc, total=len(sat_datas_train)):\n",
    "    x_train = sat_data[features]\n",
    "    y_train = sat_data[targets]\n",
    "    train_dataset = CustomDataset(x_train, y_train, seq_len=seq_len)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "    for epoch in range(10):  # TODO: adjust number of epoches\n",
    "        for seq_train_x, train_y in train_dataloader:\n",
    "            model.zero_grad()  # refresh gradients\n",
    "            predictions = model(seq_train_x)\n",
    "            loss = criterion(predictions, train_y) \n",
    "            loss_widget.value = loss\n",
    "            loss.backward()  # compute gradients\n",
    "            optimizer.step()  # update network parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T23:06:38.341928Z",
     "start_time": "2020-02-03T23:06:38.336155Z"
    }
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-03T23:31:49.520Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "display(loss_widget)\n",
    "desc = 'sattelite number'\n",
    "losses = []\n",
    "for train_data in tqdm(sat_datas_test, desc=desc):\n",
    "    x_test = sat_data[features]\n",
    "    y_test = sat_data[targets]\n",
    "    test_dataset = CustomDataset(x_test, y_test, seq_len=seq_len)\n",
    "    test_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "    for epoch in range(10):  # TODO: adjust number of epoches\n",
    "        for seq_train_x, train_y in train_dataloader:\n",
    "            predictions = model(seq_train_x)\n",
    "            loss = criterion(predictions, train_y) \n",
    "            loss_widget.value = loss\n",
    "            losses.append(loss)\n",
    "score = torch.tensor(losses).mean()\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T22:50:18.027460Z",
     "start_time": "2020-02-03T22:50:17.963113Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T22:50:18.076028Z",
     "start_time": "2020-02-03T22:50:18.032113Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T22:50:18.193531Z",
     "start_time": "2020-02-03T22:50:18.081176Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T22:52:39.840801Z",
     "start_time": "2020-02-03T22:50:18.198970Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T22:41:23.560934Z",
     "start_time": "2020-02-03T22:41:23.550574Z"
    }
   },
   "outputs": [],
   "source": [
    "model.hidden_cell[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T02:06:28.472885Z",
     "start_time": "2020-02-03T01:54:02.424Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_pred = model(x_test)\n",
    "after_train = criterion(y_pred.squeeze(), y_test) \n",
    "print('Test loss after Training' , after_train.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-03T01:54:02.426Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T02:06:28.475343Z",
     "start_time": "2020-02-03T01:54:02.429Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T19:59:30.941239Z",
     "start_time": "2020-02-02T19:59:30.925435Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
